---
title: 'AI Safety Unconference at NeurIPS 2022'
date: 2022-11-05
draft: false
---

The AI Safety Unconference brings together persons interested in aspects of AI safety, from technical AI safety problems to issues of governance of AI. As an unconference, it aims to foster valuable social interactions between participants, through moderated discussion groups, one-on-ones, lightning talks, free-form interactions.

**Date**: Monday November 28 from 9:00 to 16:00, in New Orleans, alongside NeurIPS 2022.

**Location**: Near the Convention Center - exact location to be communicated directly with registered participants.


## Participate

Fill the **[Application form](https://airtable.com/shr5uLL4tkTuHKOQh)**.

The event is private, free, with a maximum of 100 participants. Applications are open until November 20th, 2022.

Join the [chat room on Matrix](https://matrix.to/#/!kTsOmBGiyQWKmETKhS:one.ems.host?via=one.ems.host), to discuss online before or during the event.

Contribute facilitated discussion (30 min) or a lightning talk (10min). We also welcome other ideas of activities - feel free reach out to the organizers about that.

**You are also invited to the ML Safety Social**. It is happening on Tuesday at the Convention Center. Visit the [event's website](https://www.mlsafety.org/social) for further information and to apply.


## Agenda

- 09:00-09:30 - Event opening, breakfast is served
- 09:30-12:00 - Facilitated discussions and 1:1s
- 12:00-13:30 - Lightning talks, lunch is served
- 13:30-15:30 - Facilitated discussions and 1:1s
- 15:30-16:00 - Event closing

Vegan breakfast and lunch are provided, along with all-day drinks and snacks.

The [Swapcard](https://www.swapcard.com/app/swapcard) app is used for scheduling 1:1 meetings with other participants and registering to facilitated discussions.


## Further information

**Testimonial of past events** ([2018](https://aisafetyunconference.info/2018), [2019](https://aisafetyunconference.info/2019)):

- A great way to meet the best people in the area and propel daring ideas forward. — [Stuart Armstrong](https://www.fhi.ox.ac.uk/team/stuart-armstrong/)
- The event was a great place to meet others with shared research interests. I particularly enjoyed the small discussion groups that exposed me to new perspectives. — [Adam Gleave](https://www.gleave.me/)

**Background readings**:

- Center for AI Safety's [About AI Risk](https://safe.ai/about-ai-risk)
- [Krakovna's AI safety resources](https://vkrakovna.wordpress.com/ai-safety-resources)
- [Alignment newsletter](https://rohinshah.com/alignment-newsletter/)
- [Superintelligence: Paths, Dangers, Strategies](https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies) by Nick Bostrom

The event is also published on the [EA forum](https://forum.effectivealtruism.org/posts/Z9Mprytde6BbkQcq2/ai-safety-unconference-neurips-2022) and the [LW forum](https://www.lesswrong.com/posts/QKdcHjoAfPJrZuFJk/ai-safety-unconference-neurips-2022).


## Acknowledgements 

The event is organized in partnership with the [Center for AI Safety](https://safe.ai/).

Organizers:

- Orpheus Lummis
- Mauricio H. Luduena

Funding by the Future Fund Regranting Program.

For any questions or feedback, reach out to [info@aisafetyevents.org](mailto:info@aisafetyevents.org).